import streamlit as st
import pandas as pd
import requests
from bs4 import BeautifulSoup
from datetime import datetime

st.set_page_config(page_title="GG-bot | Rava Edition", page_icon="游분")

def get_rava_data():
    # URL de la pizarra de acciones l칤deres de Rava
    url = "https://www.rava.com/cotizaciones/acciones"
    headers = {'User-Agent': 'Mozilla/5.0'}
    
    try:
        r = requests.get(url, headers=headers, timeout=10)
        soup = BeautifulSoup(r.text, 'html.parser')
        
        # Buscamos la tabla de cotizaciones
        tabla = soup.find('table') 
        df = pd.read_html(str(tabla))[0]
        
        # Limpiamos el DataFrame (Rava suele traer columnas con nombres espec칤ficos)
        # Seleccionamos: Especie, 칔ltimo, % D칤a, Compra, Venta
        df = df.iloc[:, [0, 1, 2, 3, 4]]
        df.columns = ['Especie', '칔ltimo', 'Var %', 'Compra', 'Venta']
        return df
    except Exception as e:
        st.error(f"No se pudo conectar con Rava: {e}")
        return None

# --- INTERFAZ ---
st.title("游분 GG-bot | Monitor Rava")
st.caption("Datos obtenidos de la pizarra p칰blica de Rava Burs치til")

# Secci칩n de Saldo (API IOL v1 - La 칰nica que te anda)
with st.expander("游눯 Mi Billetera (IOL Real Time)"):
    st.metric("Saldo Disponible", "ARS 76.71")

st.divider()

if st.button("游댃 Actualizar Pizarra Rava"):
    with st.spinner("Conectando con Rava..."):
        df_rava = get_rava_data()
        
        if df_rava is not None:
            # Filtramos solo las que te interesan para que no sea gigante
            interes = ["GGAL", "YPFD", "PAMP", "ALUA", "EDN", "TXAR"]
            df_filtro = df_rava[df_rava['Especie'].isin(interes)]
            
            st.subheader("游늳 Acciones L칤deres")
            st.table(df_filtro)
            
            with st.expander("Ver panel completo"):
                st.dataframe(df_rava)
        else:
            st.warning("La pizarra no est치 disponible en este momento.")

st.sidebar.info(f"칔ltima consulta: {datetime.now().strftime('%H:%M:%S')}")
